Metadata-Version: 2.2
Name: advanced-scraper
Version: 1.0.0
Summary: An advanced web scraper with AI capabilities and real-time updates
Author: Your Name
Author-email: Your Name <your.email@example.com>
License: MIT
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Internet :: WWW/HTTP :: Dynamic Content
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: Flask
Requires-Dist: Flask-SQLAlchemy
Requires-Dist: Flask-Login
Requires-Dist: Flask-WTF
Requires-Dist: Werkzeug
Requires-Dist: aiohttp
Requires-Dist: requests>=2.25.1
Requires-Dist: beautifulsoup4
Requires-Dist: lxml
Requires-Dist: matplotlib
Requires-Dist: seaborn
Requires-Dist: yt-dlp
Requires-Dist: schedule
Requires-Dist: asyncio
Requires-Dist: tweepy
Requires-Dist: python-dotenv
Requires-Dist: httpx
Requires-Dist: quart-auth
Requires-Dist: quart
Requires-Dist: hypercorn
Requires-Dist: scrapy
Requires-Dist: pandas
Requires-Dist: numpy
Requires-Dist: scikit-learn
Requires-Dist: tensorflow
Requires-Dist: keras
Requires-Dist: transformers
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Dynamic: author
Dynamic: requires-python

# Multi-Platform Video Scraper

An advanced web application that searches and aggregates videos from multiple platforms including YouTube, Vimeo, and Dailymotion. Features browser rotation and anti-detection measures.

## Features

- Multi-platform video search (YouTube, Vimeo, Dailymotion)
- Asynchronous scraping for better performance
- Browser rotation to avoid detection
- Modern, responsive UI with dark mode support
- Platform filtering
- Embedded video players

## Installation

### Option 1: Basic Installation

1. Make sure you have Python 3.8+ installed

2. Clone this repository:
```bash
git clone <your-repo-url>
cd scrape
```

3. Create a virtual environment (recommended):
```bash
python -m venv venv
```

4. Activate the virtual environment:
- Windows:
```bash
venv\Scripts\activate
```
- Linux/Mac:
```bash
source venv/bin/activate
```

5. Install requirements:
```bash
pip install -r requirements.txt
```

### Option 2: Development Installation

For development or contributing to the project:

1. Follow steps 1-4 from Option 1

2. Install in development mode:
```bash
pip install -e .
```

3. Install with development dependencies (includes testing and linting tools):
```bash
pip install -e .[dev]
```

### Option 3: Package Installation

To install directly as a package:

```bash
pip install advanced-scraper
```

## Usage

1. Start the server:
```bash
python scrape_updated.py
```

2. Open your web browser and go to:
```
http://localhost:5000
```

3. Enter your search query and click "Search" or press Enter

## Troubleshooting

If you encounter SSL certificate errors while installing packages:
```bash

```

If you get browser driver errors:
1. Make sure you have Chrome, Firefox, or Edge installed
2. The webdriver-manager should automatically download the appropriate driver

## Requirements

- Python 3.8+
- Modern web browser (Chrome, Firefox, or Edge)
- Internet connection

## Dependencies

- requests
- beautifulsoup4
- selenium
- fake-useragent
- quart
- hypercorn
- requests-html
- aiohttp
- python-dotenv
- webdriver-manager
- lxml

## Note

This scraper is for educational purposes only. Please respect the terms of service and robot.txt files of the platforms you're scraping.
